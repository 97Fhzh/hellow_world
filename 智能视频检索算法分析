智能视频检索算法原理分析（一）

1    背景

智能视频检索依赖于视频算法对视频内容进行分析，通过提取视频中关键信息，进行标记或者相关处理，并形成相应事件和告警的监控方式，人们可以通过各种属性描述进行快速检索。如果把摄像机看作人的眼睛，而智能视频监控系统可以理解为人的大脑。智能视频技术借助处理器的强大计算功能，对视频画面中的海量数据进行高速分析，获取人们需要的信息;

      主要流程：

      运动分析->目标检测与追踪->光损处理->关键帧提取->特征提取->特征索引->搜索->图像排序->检索


 

2     基本概念

摄像机采集到的视频流是有非常多帧组成的，每一帧是一个图像，每个图像又由很多像素组成；

2.1      图片的像素和分辨率

      对于像素和分辨率这两个词，主要见于图片和显示设备上。

像素是组成图象的最基本单元要素：点。分辨率是指在长和宽的两个方向上各拥有的像素个数。一个像素有多大呢？主要取决于显示器的分辨率，相同面积不同分辨率的显示屏，其像素点大小就不相同。

每一个长度方向上的像素个数乘以每一个宽度方向上的像素个数的形式表示，就叫做图片的分辨率。如一张640X480的图片，表示这张图片在每一个长度的方向上都有640个像素点，而每一个宽度方向上都480个像素点，总数就是640X480=307200（个像素），简称30万像素。

显然单位面积上像素点越多即像素点越小，这图片就越清晰细腻。

2.2       图像的深度：

图片是由一个个像素点构成的，所有不同颜色的像素点构成了一副完整的图像，计算机存储图片是以二进制来进行的。

1 bit : 用一位来存储，那么这个像素点的取值范围就是0或者1，那么我们看来这幅图片要么是黑色要么是白色。

4 bit : 取值范围为 0 到 2 的4次方

8 bit : 来存储像素点的取值范围为 0 到 2 的8次方

以此类推，我们把计算机存储单个像素点所用到的bit为称之为图像的深度.

2.2.1      图像的通道：

我们知道了图片的深度信息，如果是24位的图片他的取值范围为 0 到 2的24次方，这个取值范围是相当的庞大的，那怎么根据图片某像素的深度值来确定那一像素点的颜色呢？

我们都知道颜色的三元素 Red, Green, Blue. 如果是深度为24=3*8，我们刚好就可以用第一个8位存储Red值，第二个存储Green值，第三个存储Blue值, 2的8次方刚好是255,所以我们一般看到的RGB值都是(0-255,0-255,0-255)这样的值。如果用rgb来表示图片的颜色值，我们称这样的图片通道为三。

三通道图片每个像素都是一个数组，分别包含Red, Green, Blue三个对应值，比较不同帧之间的差别时，通常采用比较每个像素点RGB值或根据各个像素点建立的数学模型的方式；

3    算法模型

3.1  背景建模与前景提取

视频分析，首先需要从每帧图片中提取到目标对象（人、车、物品等），这里主要有两步：背景建模与前景提取；

     在智能视频监控领域,背景建模是一项关键技术,建模的结果将对视频图像的运动目标检测、运动目标分类、跟踪及行为理解等后续处理产生重要影响，目前业界有很多背景建模相关算法；

     前景提取，就是当前图片，去除背景建模提取出的背景、噪声、阴影等干扰信息之后所获取的目标对象；

首先，从输入视频中选取部分帧作为样本，通过背景建模算法进行背景提取，提取到背景后，将当前帧与背景逐个像素点进行比对，是背景的像素置为0，否则置为1，由此得到一个掩膜图像（Mask），初步获得的掩膜图像因为遮挡、阴影、干扰信息等因素，可能是不清晰的，所以需要对Mask进行修复处理，主要采用相邻像素的相似性比对；Mask修复完之后，就得到了完整、清晰的前景（目标）区域，之后将当前帧与Mask进行比对，就可以提取到目标对象（人、车、动物等）；

典型背景建模算法模型介绍：

3.1.1      帧差模型


      帧差可说是最简单的一种背景模型，指定视频中的一幅图像为背景，用当前帧与背景进行比较，根据需要过滤较小的差异，得到的结果就是前景了。

3.1.2      背景统计模型

   背景统计模型是：对一段时间的背景进行统计，然后计算其统计数据（例如平均值、平均差分、标准差、均值漂移值等等），将统计数据作为背景的方法。

3.1.3      编码本背景模型

 编码本的基本思路是这样的：针对每个像素在时间轴上的变动，建立多个（或者一个）包容近期所有变化的Box（变动范围）；在检测时，用当前像素与Box去比较，如果当前像素落在任何Box的范围内，则为背景。

3.1.4      混合高斯模型

混合高斯背景建模是背景建模比较成功的一种。

为什么这么说呢？ 机器视觉算法提取运动目标面临的基本问题：图像抖动，噪声干扰，光线变化，云飘动，阴影（包括目标阴影和区域外物体阴影），区域内部反光（如水面，显示器），运动目标缓慢移动等。那我们来看看，混合高斯背景建模是怎么解决这些问题的？从混合高斯模型的原理一看便知。


混合高斯模型的原理

　　图像中每个像素点的值（或特征）短时间内都是围绕与某一中心值一定距离内分布，通常，中心值可以用均值来代替，距离呢可以用方差来代替。这种分布呢是有规律的，根据统计定律，如果数据点足够多的话，是可以说这些点呈正态分布，也称为高斯分布（取名高斯，大概是因为很多地方都用这个名字吧）。根据这个特点，如果像素点的值偏离中心值较远，那么，这个像素值属于前景，如果像素点的值偏离中心值很近（在一定方差范围内），那么可以说这个点属于背景。理论上，如果不存在任何干扰的话，是可以准确区分前景和背景的。但是，现实往往不尽如人意，如果画面中光线变化的话，这个高斯分布的中心位置是会改变的。如果光线强度改变的话，在原来那个位置并没有无数个点供统计，因此，不符合大数定理，也就不能说那个点的分布满足正态分布了，只能说是近似为高斯分布。

　　混合高斯模型指这个像素点值存在多个中心位置，如来回摆动的树叶，波光粼粼的水面，闪烁的显示器，图像中特征边缘位置的抖动等，这些都会引起某个像素点会在多个中心位置聚集大量的点，每个位置便会产生一个高斯分布，四个以上的高斯分布其实并不常见，这便是混合高斯模型的由来。混合高斯背景建模主要用来解决背景像素点具有多峰特性的场合，如在智能交通场景中，解决视频画面抖动带来的干扰。

　　针对光线变化的问题，混合高斯模型通过比较当前像素点的值与高斯分布中心位置，选择一定的加权系数对当前高斯分布的中心位置进行更新，以便于适应缓慢的光线变化。言外之意，高斯分布并不能解决光线的突变问题，如云飘动，阴影。个人认为，阴影或云飘动并不属于背景建模的内容。

　　此外，混合高斯模型尤其适合于检测缓慢移动的物体，因为背景已是一个高斯分布，如果车停下来，等到聚集一定的前景数据便会形成一个新的高斯分布，停下来的车也会便是背景。但是如果车缓慢行驶的话，是很难在短时间内形成一个新的高斯分布，也就是应用混合高斯分布很容易检测缓慢行驶的车辆。

混合高斯背景建模的优点

　　图像画面中，其实每个像素（也可以说是局部单元），其运动变化特性是不一样的，这才是混合高斯模型具有优势的主要原因。普通的二值化目标分割，整个画面采用同一阈值，无论这个阈值是固定的，还是自适应的，都存在本质性的缺陷，属于有缺陷的分割，这种算法带有不稳定性，无论怎么调整分割参数，也解决不了根本性的问题。因为，画面中每个部分，其实分割阈值是不一样的。一定得建立统计学的方法，进行局部分割，而混合高斯模型正是采用局部分割的一种算法。

混合高斯背景建模方法评价

　　从理论上来说，混合高斯背景建模真是一种较为完美的背景分割方法。但是由于像素值在光线干扰下在中心位置停留时间较短，围绕这一中心位置波动的数据准确地来说并不属于高斯分布，因此也就无法准确地确定这些数据的中心值及方差，造成实际分割的效果并不完美。

 

3.2  目标检测与跟踪

通过背景建模与前景提取，把视频帧中的目标对象提取了出来，不过提取得到的是所有非背景对象，也就是是混合的，可能包含很多人、车、动物等对象，最终以图搜图检索所要对比的是当个对象与搜索目标的相似性，这里就需要通过目标检测与跟踪把这些混合的对象分离开来分别处理；

在目标检测方面，所了解到的算法有贝叶斯方法、卡尔曼滤波器、粒子滤波器几种，他们之间的关系如下：

贝叶斯方法利用已知的信息建立系统的概率密度函数可以得到对系统状态估计的最优解。

对于线性高斯的估计问题，期望的概率密度函数仍是高斯分布，它的分布特性可用均值和方差来描述，卡尔曼滤波器很好地解决了这类估计问题。

粒子（particle）滤波器——序列重要性采样粒子滤波器，是一种适用于强非线性、无高斯约束的基于模拟的统计滤波器。

综合上，粒子滤波的效果要更好；

3.3  光照处理

     同一个物体，在不同光照下的视觉效果是不同的，所对应的数据也是不同的，所以，为了提高分析准确性，召回率，需要对目标对象做光照处理；光照处理方面，业界比较流行的算法是本征图像分解法；

3.3.1      本征图像分解

照相机所获得的图像中的每个像素点值所具有的属性所表示的信息中最为重要的是亮度(shading)和反照率(reflectance)这两种。其中亮度对应环境中的光照信息,反照率对应于物体的材质信息,即物体对光照的反射特性,反照率主要表现为物体的颜色信息。本征图像求解问题就是从图像出发,恢复所有像素点对应的场景中的亮度和反照率信息,分别形成亮度本征图和反照率本征图

本征图像分解可以表述为I(x,y) = L(x,y)R(x,y),其中I(x,y)表示输入图像, R(x,y)表示反照率图像, L(x,y)表示亮度图像。因为在对数域中,乘法被转换成了更加易于计算的加法,因此我们在图像的对数域中进行计算,记 /(X,y) = log(I(x, y)) , r0,y) = log(R(x,少)),l(x,y) = log(L(x,y))。如此原来的乘法关系被转化为:i(x,y,t) = r(x,y) + l(x,y,t)。

3.4  关键帧提取

安防监控所采集的视频数据量非常大，如果对视频的每一帧都进行特征提取、建立高维索引、检索，那么在视频分析和检索方面的时间开销将非常大，所以第一步，要先对视频流进行关键帧提取，只对关键帧进行特征提取、建立高维索引、检索的操作，大幅度缩短计算量；

视频关键帧提取是指按照一定的规则提取能够代表原视频内容的帧，该技术能够去除视频数据中大部分冗余信息，仅保留视频数据有用的部分；关键帧提取是后续特征提取。索引建立的前提，算法的优劣会直接影响整个视频分析的准确率和性能；

关键帧提取的方法

关键帧提取方法主要分为两类：基于全图像序列的方法和基于压缩视频的方法；  

目前大多数关键帧的提取研究是基于全图像视频分析的．具体实现方法的区别主要在于检测方法的应用、特征的选择以及帧图像子块的划分。主要可以分为以下几类：

3.4.1     基于镜头边界的方法

该方法将视频流分割成很多的镜头，把镜头中的第一帧和最后一帧以及中间几帧作为关键帧。该方法简单易行，适于内容活动性小或内容保持不变的镜头。但未考虑镜头视觉内容的复杂性：限制了镜头关键帧的个数：提取的关键帧代表性不强，效果不够稳定。

3.4.2     基于内容分析的方法

该方法基于每一帧的颜色、纹理等视觉信息的改变来提取关键帧。比较经典的方法是帧平均法和直方图平均法。帧平均法是在镜头中计算所有帧在某个位置上像素值的平均值．然后将镜头中该点位置的像素值最接近平均值的帧作为关键帧；直方图平均法是将镜头中所有帧的统计直方图取平均．然后选取与该平均直方图最接近的帧作为关键帧。

3.4.3     基于运动分析的方法

此方法是根据运动信息提取关键帧．代表算法是Wolf提出的运动极小值算法 Wolf通过光流分析来计算镜头中的运动量．在运动量取局部最小值处选取关键帧。

3.4.4     基于聚类的方法

该方法是目前关键帧提取的主流技术．其基本思想是：首先确定一个初始类心．然后根据当前帧与类心的距离来判断当前帧是归为该类还是作为新的类心．将镜头中帧分类后．取各类中离类心距离最近的帧作为关键帧。

3.4.5     基于压缩视频的方法

上述方法都是基于全图像序列的，即在提取关键帧之前．对视频进行解压，还原成帧图像。运算量大。基于压缩域的方法是直接从MPEG压缩视频流上提取关键帧．无需对视频流解压或只需部分解压，降低了计算的复杂性。

 

     业界比较常用的是基于聚类的方法和基于压缩域的方法进行关键帧提取；

 

     关键帧提取完成后，就需要对提取到的关键帧进行特征提取操作，主要是颜色特征、纹理特征、形状特征等几个角度；特征提取完成后，会对目标特征建立高维索引，来提高检索速度，最后通过对索引进行检索来搜索目标图像，返回搜索结果；

     特征提取，高维索引，图像检索方面的算法后续再做介绍；

 
