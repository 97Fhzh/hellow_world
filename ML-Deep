分布式TensorFlow中ps、worker、in-graph、between-graph、synchronous training和asynchronous training的概念
在大数据和分布式的场景下一般使用异步训练
通过Google Cloud ML服务，我们可以把TensorFlow应用代码直接提交到云端运行，甚至可以把训练好的模型直接部署在云上，通过API就可以直接访问

1. 准备训练数据
2. 接受命令行参数
3. 定义神经网络模型
4. 使用不同的优化算法
5. Online learning与Continuous learning
6. 使用TensorBoard优化参数
7. 分布式TensorFlow应用
8. Cloud Machine Learning

TF的四大核心概念：计算图，操作，变量，会话。
 计算图：又被称为有向图和数据流图。节点用来表示施加的数学操作，数据输入的起点/输出的终点，读取/写入持久变量的终点。线表示节点之间的输入/输出关系。
 张量就是大小可以动态调整的多维数据数组。
 
 前向预测建模 ---> 损失部分建模 ---> 训练过程建模
 
 运算操作
一个运算操作代表了一种类型的抽象运算，比如矩阵乘法或者向量加法。
一个运算符可以有自己的属性，但是所有的属性都必须被提前设置。
通过设置运算操作的属性可以用来支持不同的tensor元素类型。
运算核是一个运算操作在某个具体的硬件的实现。
可以通过注册机制加入新的运算操作符或者为已有的运算操作添加新的计算核。
标量运算，向量运算，矩阵运算，带状态的运算，神经网络组件，存储，恢复（tf.train.Saver对象），队列及同步运算，控制流

 
